# LangChain 说明

官方地址： https://github.com/hwchase17/langchain   
文档： https://python.langchain.com/en/latest/ 重要，特别是 agent 部分   
官方博客：https://blog.langchain.dev/   
非官方中文教程： https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng/ 写的很好   
awesome: https://github.com/kyrolabs/awesome-langchain   
B 站上面有很多： https://search.bilibili.com/all?keyword=LangChain 但是没发现真正啥有用的   

LangChain 目标是将 LLM 与开发者现有的知识和系统相结合，以提供更智能化的服务。众所周知 OpenAI 的 API 无法联网的，所以如果只使用自己的功能实现联网搜索并给出回答、总结 PDF 文档、基于某个 Youtube 视频进行问答等等的功能肯定是无法实现的，强大的 LangChain 可以做到这个事情

它赋予LLM两大核心能力
- 数据感知，将语言模型与其他数据源相连接
- 代理能力，允许语言模型与其环境互动。

LangChain 是一个用于开发由语言模型驱动的应用程序的框架。他主要拥有 2 个能力：

- 可以将 LLM 模型与外部数据源进行连接
- 允许与 LLM 模型进行交互

LangChain 的主要应用场景包括个人助手、基于文档的问答、聊天机器人、查询表格数据、代码分析等。应用非常广泛，例如 VisualChatGPT 就是使用了这个库进行规划和执行特定函数。

它逻辑上主要有6大模块：llms、prompt、chains、agents、memory、indexes。

LangChain主要包括以下几个主要的模块：

- Prompt Templates：支持自定义Prompt工程的快速实现以及和LLMs的对接；
- LLMs：提供基于OpenAI API封装好的大模型，包含常见的OpenAI大模型，也支持自定义大模型的封装；
- Utils：大模型常见的植入能力的封装，比如搜索引擎、Python编译器、Bash编译器、数据库等等；
- Chains（重点）：大模型针对一系列任务的顺序执行逻辑链；
- Agents（重点）：通常 Utils 中的能力、Chains 中的各种逻辑链都会封装成一个个工具（Tools）供 Agents 进行智能化调用，从而具备了调用插件功能

其中，Chains 和 Agents 两个模块是 LangChain 的亮点。

注意： GPT3.5 模型本身是不支持多轮对话的，ChatGPT 其实是在 GPT3.5 之上植入了 Memory 实现了多轮对话的能力。也就是说我们经常和 LLM 进行对话，实际上他本身不具备连续对话能力，只不过程序员会维持一个可自定义的 memory bank
每次聊天时候都会把前后文发过去，所以才有了连续对话能力。

REACT 技术 (Reason+Act): https://arxiv.org/pdf/2210.03629.pdf   
LLM 的 ReAct 模式的 Python 实现: https://til.simonwillison.net/llms/python-react-pattern   
执行过程：https://blog.csdn.net/qq_35361412/article/details/129797199 写的非常详细，强烈推荐   

## langchain-ChatGLM 学习记录

基于 ChatGLM 的本地知识库 QA 应用

<div align=center>
<img src="https://user-images.githubusercontent.com/17425982/235078705-dc362fc9-21b4-45d3-ba2d-e40d49638f74.png"/>
</div>

项目地址：https://github.com/imClumsyPanda/langchain-ChatGLM   
在线可运行地址：https://www.heywhale.com/mw/project/643977aa446c45f4592a1e59   

实现原来看起来比较简单：

1. 下载 GanymedeNil/text2vec-large-chinese 支持中文的 Embedding 模型
2. 用户上传一份或者多份文档，注意由于内部是采用 langchain 来自动解析，应该需要符合一定格式。
3. 对上传文档进行一些处理，输入到 Embedding 模型中得到 vectors
4. 用户给定一个问题，先将该问题转换成 vector，然后计算与文档中每个 vector 的相似度，取 topk 个 vector。
5. 对查询出来的 topk 个 vector 反向查找文本字符串，将其和用户输入组成 prompt 输入给 ChatGLM 模型，得到答案。

如果失败，则原因在于 

- embedding 没找对 top-k
- chatglm 的 openqa 精度还有提升空间

将片段文转为向量，并将向量和原片段文本存到向量数据库，在用户提问时，先将提问的文本转为向量，在向量数据库查找相近向量的原片段，将原片段拼接为上下文，将用户问题和拼接的上下文发给chatgpt返回结果.

一个更大的类似的项目是： 

- https://github.com/yanqiangmiffy/Chinese-LangChain
- https://github.com/hwchase17/chat-langchain

## visual chatgpt

Visual ChatGPT 原理：https://medium.com/mlearning-ai/visual-chatgpt-paper-and-code-review-ffe69ff16671   
看完这个博客 https://blog.csdn.net/qq_35361412/article/details/129797199 就知道 visual chatgpt 运行原理了。核心还是构建 prompt ，然后一切交给 LLM 就行。langchain 的应用。

### hugginggpt

论文地址： https://arxiv.org/pdf/2303.17580.pdf   
官方地址：https://github.com/microsoft/JARVIS/blob/main/server/run_gradio_demo.py   

代码写的比较简单，没有用 langchain 库，看起来比较容易。做法实际上和 visualGPT 一样，但是 visualGPT 用了 langchain，代码虽然看起来比较简洁，但是比较难理解。

<div align=center>
<img src="https://user-images.githubusercontent.com/17425982/235107725-848c048f-4724-4efe-b771-e7f61eb02d1c.png"/>
</div>

看图可以知道其干了啥。这个流程要 work，一个必备前提是超强 LLM，否则任何一步都可能失败了。

总的来说要实现任务自动调度，或者说 autoGPT 功能，需要按照顺序执行如下步骤：

1. 用户输入一个超长的包括各种要求的 prompt，Can you describe what this picture depicts  and count how many objects in the picture? 注意输入要给定图片，实际上只要给定真正存在的图片路径就行，不需要提前自己读取和解析啥的，因为后面的 task 会自动处理
2. 解析任务阶段：基于用户给定的 prompt 和预定的超长 prompt  #1 Task Planning Stage: The AI 来进行自动任务规划，这个 prompt 其实类似一个多选任务，里面包括了所有应该支持的任务。因为要明确的告诉 LLM 有哪些任务可以选择，不然没法处理
3. 上面的人为构建的 prompt 调用 llm 后就会输出所以应该需要的 task，并且会输出执行依赖和顺序。这个就非常考验 LLM 能力，如果能力稍微弱一点就做不到了。
4. 模型选择部分：注意不是所有模型都是要进行选择的，只有某些功能相同的模型需要再次提供 prompt 给 LLM 进行选择(选择已经是每个 model 的描述和 like 字段)，代码里面有部分 hard code。存在的问题是： 在进行模型选择时候，输入的只是 task 文本，按照道理来说选择的模型每次都一样才是(
可能还是有点动态，以 text2video 为例，不同的图片会产生不同的描述，这个描述而不同描述会输入到 prompt 中进行模型选择，由于描述参数不一样，可能选择的模型也不一样)。看样子目前无法处理：请选择一个最轻量化的检测模型，因为目标检测的输入只是图片，而没有文本，因此模型选择时候 prompt 应该是一样的。
5. 任务执行阶段： 基于前面规划好的任务，开启多进程执行即可，得到每个任务的输出
6. 结果收集阶段： 将前面收集到的所有数据，按照特定的 prompt形式组织再次输入给 llm，让他进行总结，最终就输出了一个包括详细过程的响应输出

可以发现整个过程的核心就是 prompt 构建，构建好后无脑的丢给 llm 就行了。用户其实 hard code 地方不多。

<div align=center>
<img src="https://user-images.githubusercontent.com/17425982/235113570-f49d24bb-9f80-4a56-9d56-4394eaa6d00e.png"/>
</div>

上图就是所有的 prompt，理解了这个表就理解了这个做法。

**如果想让去其他模型也具备 langchain 功能，例如完成类似 hugginggpt 功能和 visual chatgpt 功能，只需要把模型部署到本地，直接通过 post 方式访问，就可以直接换掉 LLM 了。**

### 实战1

代码见 [this](demo_1.py)

下面分析详细的运行过程。

Agent 对象用于协调整个运行过程，核心功能是 plan, 用于规划和决策每一步需要做啥事情。核心流程为;

```python
# langchain/chains/base.py
def __call__(
    self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False
) -> Dict[str, Any]:
    """Run the logic of this chain and add to output if desired.
    Args:
        inputs: Dictionary of inputs, or single input if chain expects
            only one param.
        return_only_outputs: boolean for whether to return only outputs in the
            response. If True, only new keys generated by this chain will be
            returned. If False, both input keys and new keys generated by this
            chain will be returned. Defaults to False.
    """
    # 如果有 memory 就也加进去，然后进行校验，看下输入是否合法
    inputs = self.prep_inputs(inputs) # 准备当前 chain 的输入
    self.callback_manager.on_chain_start( # 回调函数
        {"name": self.__class__.__name__},
        inputs,
        verbose=self.verbose,
    )
    try:
        outputs = self._call(inputs) # 运行一次
    except (KeyboardInterrupt, Exception) as e:
        self.callback_manager.on_chain_error(e, verbose=self.verbose)
        raise e
    self.callback_manager.on_chain_end(outputs, verbose=self.verbose) # 回调函数
    return self.prep_outputs(inputs, outputs, return_only_outputs) # 解析输出
```

注意： 由于 Agent 是一个循环智能体，并且也是属于 Chain 的子类，因此可能会出现上述 `__call__` 调用多次的情况，因为调用一次表示 plan 了一次，而一个任务可能需要 plan多次。一旦接收到 AgentFinish 就完成了。

```python
# langchain/chains/base.py 这个是通用的，不是核心
def prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]:
    """Validate and prep inputs."""
    if not isinstance(inputs, dict):
        _input_keys = set(self.input_keys)
        if self.memory is not None:
            # If there are multiple input keys, but some get set by memory so that
            # only one is not set, we can still figure out which key it is.
            _input_keys = _input_keys.difference(self.memory.memory_variables)
        inputs = {list(_input_keys)[0]: inputs}
    if self.memory is not None:
        external_context = self.memory.load_memory_variables(inputs)
        inputs = dict(inputs, **external_context) # 核心，如果没有 memory 则直接验证后返回
    self._validate_inputs(inputs)
    return inputs
```

_call_ 是核心：

```python
# /langchain/agents/agent.py#AgentExecutor 
# 通用方法，用于控制如何 plan,何时停止
def _call(self, inputs: Dict[str, str]) -> Dict[str, Any]:
    """Run text through and get agent response."""
    # Construct a mapping of tool name to tool for easy lookup
    name_to_tool_map = {tool.name: tool for tool in self.tools}
    # We construct a mapping from each tool to a color, used for logging.
    # llm 输出在调用不同工具输出时候采用不同颜色显示，方便用户区分
    color_mapping = get_color_mapping(
        [tool.name for tool in self.tools], excluded_colors=["green"]
    )
    intermediate_steps: List[Tuple[AgentAction, str]] = []
    # Let's start tracking the number of iterations and time elapsed
    iterations = 0
    time_elapsed = 0.0
    start_time = time.time()
    # 控制何时停止，最大迭代 15 次
    # We now enter the agent loop (until it returns something).
    while self._should_continue(iterations, time_elapsed):
        # 进行一次 plan，内部会调用 LLMSingleActionAgent 进行一次 plan
        next_step_output = self._take_next_step(
            name_to_tool_map, color_mapping, inputs, intermediate_steps
        )
        
        # 如果接收到 AgentFinish 则停止
        if isinstance(next_step_output, AgentFinish):
            return self._return(next_step_output, intermediate_steps)
        # 保留中间结果
        intermediate_steps.extend(next_step_output)
        
        if len(next_step_output) == 1:
            next_step_action = next_step_output[0]
            # See if tool should return directly
            # 如果工具内部有 return_direct 属性，表示也是直接返回
            tool_return = self._get_tool_return(next_step_action)
            if tool_return is not None:
                return self._return(tool_return, intermediate_steps)
        iterations += 1
        time_elapsed = time.time() - start_time
        
    # 如果超过了迭代次数或者时间还没有停止，则直接返回停止信息  
    # self 是 AgentExecutor,
    # self.agent 是 LLMSingleActionAgent
    output = self.agent.return_stopped_response(
        self.early_stopping_method, intermediate_steps, **inputs
    )
    # 返回
    return self._return(output, intermediate_steps)
```

以上就是  Agent 的通用核心调度过程。

**需要理解 AgentExecutor，LLMSingleActionAgent 和 LLMChain 的关系，三者实际上都是 Chain 的子类。**

```python
# /langchain/agents/agent.py#AgentExecutor 
# 开始进行一步 plan
def _take_next_step(
    self,
    name_to_tool_map: Dict[str, BaseTool],
    color_mapping: Dict[str, str],
    inputs: Dict[str, str],
    intermediate_steps: List[Tuple[AgentAction, str]],
) -> Union[AgentFinish, List[Tuple[AgentAction, str]]]:
    """Take a single step in the thought-action-observation loop.
    Override this to take control of how the agent makes and acts on choices
    """
    
    # Call the LLM to see what to do.
    # 核心流程，调用 LLMSingleActionAgent 进行一次调用，返回 llm 输出
    output = self.agent.plan(intermediate_steps, **inputs)
    
    # If the tool chosen is the finishing tool, then we end and return.
    if isinstance(output, AgentFinish):
        return output
    
    # 如果没有完成，则表示要执行 actions
    
    actions: List[AgentAction]
    if isinstance(output, AgentAction):
        actions = [output]
    else:
        actions = output
    result = []
    # 可以顺序执行
    for agent_action in actions:
        # 回调函数
        self.callback_manager.on_agent_action(
            agent_action, verbose=self.verbose, color="green"
        )
        # Otherwise we lookup the tool
        if agent_action.tool in name_to_tool_map:
            tool = name_to_tool_map[agent_action.tool]
            return_direct = tool.return_direct
            color = color_mapping[agent_action.tool]
            tool_run_kwargs = self.agent.tool_run_logging_kwargs()
            if return_direct:
                tool_run_kwargs["llm_prefix"] = ""
            # We then call the tool on the tool input to get an observation
            # 调用工具，返回 observation
            observation = tool.run(
                agent_action.tool_input,
                verbose=self.verbose,
                color=color,
                **tool_run_kwargs,
            )
        else:
            tool_run_kwargs = self.agent.tool_run_logging_kwargs()
            observation = InvalidTool().run(
                agent_action.tool,
                verbose=self.verbose,
                color=None,
                **tool_run_kwargs,
            )
        result.append((agent_action, observation)) # 结果返回
    return result
```

开始进行 plan

```python
# langchain/agents/agent.py#LLMSingleActionAgent
def plan(
    self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any
) -> Union[AgentAction, AgentFinish]:
    """Given input, decided what to do.
    Args:
        intermediate_steps: Steps the LLM has taken to date,
            along with observations
        **kwargs: User inputs.
    Returns:
        Action specifying what tool to use.
    """
    # llm_chain 就是 LLMChain
    output = self.llm_chain.run(
        intermediate_steps=intermediate_steps, stop=self.stop, **kwargs
    )
    return self.output_parser.parse(output) # 会调用 CustomOutputParser 对结果进行解析
```

```python
# /langchain/chains/llm.py#LLMChain
# self.llm_chain.run
def _call(self, inputs: Dict[str, Any]) -> Dict[str, str]:
    return self.apply([inputs])[0]

def apply(self, input_list: List[Dict[str, Any]]) -> List[Dict[str, str]]:
    """Utilize the LLM generate method for speed gains."""
    response = self.generate(input_list)
    return self.create_outputs(response) # 对 llm 返回结果进行解析

def generate(self, input_list: List[Dict[str, Any]]) -> LLMResult:
    """Generate LLM result from inputs."""
    prompts, stop = self.prep_prompts(input_list) # 基于输入，构造 prompt
    return self.llm.generate_prompt(prompts, stop) # 调用 OpenAI 接口进行生成

def prep_prompts(
    self, input_list: List[Dict[str, Any]]
) -> Tuple[List[PromptValue], Optional[List[str]]]:
    """Prepare prompts from inputs."""
    stop = None
    if "stop" in input_list[0]:
        stop = input_list[0]["stop"]
    prompts = []
    for inputs in input_list:
        selected_inputs = {k: inputs[k] for k in self.prompt.input_variables}
        # 调用用户自定义的 CustomPromptTemplate 进行格式化
        prompt = self.prompt.format_prompt(**selected_inputs)
        _colored_text = get_colored_text(prompt.to_string(), "green")
        _text = "Prompt after formatting:\n" + _colored_text
        self.callback_manager.on_text(_text, end="\n", verbose=self.verbose)
        if "stop" in inputs and inputs["stop"] != stop:
            raise ValueError(
                "If `stop` is present in any inputs, should be present in all."
            )
        prompts.append(prompt)
    return prompts, stop

def create_outputs(self, response: LLMResult) -> List[Dict[str, str]]:
    """Create outputs from response."""
    return [
        # Get the text of the top generated string.
        {self.output_key: generation[0].text} # 只是取出文本即可，然后后续会调用 CustomOutputParser 对结果进行解析
        for generation in response.generations
    ]
```

上述就完成了一次 plan 过程，迭代上述过程即可。

<div align=center>
<img src="https://user-images.githubusercontent.com/17425982/237018842-515ae4b7-5ae0-405e-bda4-bc05b2cf51e0.png"/>
</div>


# Vit-adapter

VISION TRANSFORMER ADAPTER FOR  DENSE PREDICTIONS

ICLR2023

https://github.com/czczup/ViT-Adapter


# Polyhistor

https://proceedings.neurips.cc/paper_files/paper/2022/file/efb02f96766a3b599c76852abf4d42dd-Supplemental-Conference.pdf

NeurIPS 2022

# Parameter-Efficient Low Rank Adapter for Dense Predictions

1% VS 100%: Parameter-Efficient Low Rank Adapter for Dense Predictions

CVPR2023

# Parameter-efficient is not sufficient: Exploring Parameter, Memory, and Time Efficient Adapter Tuning for Dense Predictions

https://arxiv.org/abs/2306.09729

# Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation

https://arxiv.org/abs/2307.11545

# Prompt Guided Transformer for Multi-Task Dense Prediction

https://arxiv.org/abs/2307.15362

# Probabilistic Prompt Learning for Dense Prediction

cvpr2023

https://arxiv.org/abs/2304.00779


# UniPT

UniPT: Universal Parallel Tuning for Transfer Learning with Efficient Parameter and Memory

https://arxiv.org/pdf/2308.14316.pdf

https://github.com/Paranioar/UniPT


